---
title: "Confidence in causal discovery with linear causal models"
collection: publications
permalink: /publication/Confidence-in-causal-discovery-with-linear-causal-models
date: 1 December 2021
venue: 'Proceedings of Machine Learning Research'
paperurl: 'https://proceedings.mlr.press/v161/strieder21a.html'
citation: 'D. Strieder, T. Freidling, S. Haffner and M. Drton. <i> Confidence in Causal Discovery with Linear Causal Models. </i>
Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence, PMLR 161:1217-1226, (2021).'


---


Abstract: Structural causal models postulate noisy functional relations among a set of interacting variables. The causal structure underlying each such model is naturally represented by a directed graph whose edges indicate for each variable which other variables it causally depends upon. Under a number of different model assumptions, it has been shown that this causal graph and, thus also, causal effects are identifiable from mere observational data. For these models, practical algorithms have been devised to learn the graph. Moreover, when the graph is known, standard techniques may be used to give estimates and confidence intervals for causal effects. We argue, however, that a two-step method that first learns a graph and then treats the graph as known yields confidence intervals that are overly optimistic and can drastically fail to account for the uncertain causal structure. To address this issue we lay out a framework based on test inversion that allows us to give confidence regions for total causal effects that capture both sources of uncertainty: causal structure and numerical size of nonzero effects. Our ideas are developed in the context of bivariate linear causal models with homoscedastic errors, but as we exemplify they are generalizable to larger systems as well as other settings such as, in particular, linear non-Gaussian models.


[Download paper here](https://proceedings.mlr.press/v161/strieder21a.html)

